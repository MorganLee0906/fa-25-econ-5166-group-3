---
title: "Processing Taxi Data"
output:
  html_document:
    toc: true
    number_sections: false
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# README

-   **Author**: `Yen-Chen Chou & Tung-Yen Wu`
-   **Created At**: `2025-09`
-   **Last Modified At**: `2025-12-02 by Tung-Yen Wu`

------------------------------------------------------------------------

## What does this file do?

-   Combine the raw data of fhvhv_tripdata from January 2024 to August 2025 into a single dataset; Saving them as a more efficient way (.parquet to .rds).
-   Eliminate 7 unneeded administrative columns: dispatching_base_num, originating_base_num, shared_request_flag, shared_match_flag, access_a_ride_flag, wav_request_flag, wav_match_flag.
-   Filter out trips with negative fare or fee components
-   Defining the treated regions (for those dropout in CBD)
------------------------------------------------------------------------

## What does this file take?

-   **Source Data Sets**:

    1.  `/data/raw/fhvhv_tripdata_2024-01.parquet`

    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle for January 2024.`

    2.  `/data/raw/fhvhv_tripdata_2024-02.parquet`

    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle for February 2024.`

    3.  `/data/raw/fhvhv_tripdata_2024-03.parquet`

    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle for March 2024.`

    4.  `/data/raw/fhvhv_tripdata_2024-04.parquet`

    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle for April 2024.`

    5.  `fhvhv_tripdata_2024-05.parquet`

    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle for May 2024.`

    6.  `/data/raw/fhvhv_tripdata_2024-06.parquet`

    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle for June 2024.`

    7.  `/data/raw/fhvhv_tripdata_2024-07.parquet`

    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle for July 2024.`

    8.  `/data/raw/fhvhv_tripdata_2024-08.parquet`

    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle for August 2024.`

    9.  `/data/raw/fhvhv_tripdata_2024-09.parquet`

    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle for September 2024.`

    10.  `/data/raw/fhvhv_tripdata_2024-10.parquet`

    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle for October 2024.`

    11.  `/data/raw/fhvhv_tripdata_2024-11.parquet`

    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle for November 2024.`

    12.  `/data/raw/fhvhv_tripdata_2024-12.parquet`

    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle for December 2024.`

    13.  `/data/raw/fhvhv_tripdata_2025-01.parquet`

    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle for January 2025.`

    14.  `/data/raw/fhvhv_tripdata_2025-02.parquet`

    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle for February 2025.`

    15.  `/data/raw/fhvhv_tripdata_2025-03.parquet`

    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle for March 2025.`

    16.  `/data/raw/fhvhv_tripdata_2025-04.parquet`

    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle for April 2025.`

    17.  `/data/raw/fhvhv_tripdata_2025-05.parquet`

    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle for May 2025.`

    18.  `/data/raw/fhvhv_tripdata_2025-06.parquet`

    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle for June 2025.`

    19.  `/data/raw/fhvhv_tripdata_2025-07.parquet`

    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle for July 2025.`

    20.  `/data/raw/fhvhv_tripdata_2025-08.parquet`

    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle for August 2025.`
    
------------------------------------------------------------------------

## What does this file output?

-   `/data/processed/hvfhv_cleaned_2024_01_03_combined.rds`
    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle from 2024-01 to 2024-03.`

-   `/data/processed/hvfhv_cleaned_2024_04_12_combined.rds`
    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle from 2024-04 to 2024-12.`
    
-   `/data/processed/hvfhv_cleaned_2024_01_03_combined.rds`
    -   Description: `TLC Trip Record Data of High Volume For-Hire Vehicle from 2025-01 to 2025-10.`



```{r load_and_bind_data}
library(arrow)
library(dplyr)
library(janitor)

# =========================================================
# 1. Define Directories
# =========================================================
data_dir   <- "C:/Users/hp/Desktop/fa-25-econ-5166-group-3/data/raw"
output_dir <- "C:/Users/hp/Desktop/fa-25-econ-5166-group-3/data/processed"
dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)

# =========================================================
# 2. Define treated location IDs & save as list (for later use)
# =========================================================
target_ids <- c(
  12, 13, 43, 45, 48, 50, 79, 87, 88, 90,
  100, 107, 113, 114, 125, 137, 140, 144,
  148, 151, 158, 161, 162, 163, 164, 170,
  186, 193, 209, 211, 229, 230, 231, 232,
  233, 234, 246, 249, 261
)

treated_loc_list <- list(target_ids = target_ids)
treated_loc_path <- file.path(output_dir, "treated_loc_list.rds")
saveRDS(treated_loc_list, treated_loc_path)
cat("✔ Saved treated location list to:\n  ", treated_loc_path, "\n")

# =========================================================
# 3. Helper: pretty size formatter
# =========================================================
pretty_size <- function(bytes) {
  units <- c("B", "KB", "MB", "GB", "TB")
  if (bytes <= 0 || is.na(bytes)) return("0 B")
  exp <- floor(log(bytes, 1024))
  exp <- max(0, min(exp, length(units) - 1))
  sprintf("%.2f %s", bytes / (1024 ^ exp), units[exp + 1])
}

# =========================================================
# 4. Define groups of months (month_tag base without extension)
# =========================================================
groups <- list(
  "2024_01_03" = sprintf("fhvhv_tripdata_2024-%02d", 1:3),
  "2024_04_12" = sprintf("fhvhv_tripdata_2024-%02d", 4:12),
  "2025_01_10" = sprintf("fhvhv_tripdata_2025-%02d", 1:10)
)

# =========================================================
# 5. Prepare deletion log container
# =========================================================
delete_log <- list()

# =========================================================
# 6. For each group: read raw, clean in memory, combine, save big .rds
# =========================================================
for (g in names(groups)) {

  month_tags <- groups[[g]]   # e.g. "fhvhv_tripdata_2024-01", ...

  cat("\n=============================\n")
  cat(sprintf("Processing group: %s\n", g))

  combined_list <- list()
  idx <- 1L

  for (mt in month_tags) {

    raw_file <- file.path(data_dir, paste0(mt, ".parquet"))

    if (!file.exists(raw_file)) {
      warning(sprintf("Raw file not found for %s. Skipping this month.", mt))
      next
    }

    cat(sprintf("  - Cleaning month: %s\n", basename(raw_file)))

    # ---- Read & clean this month's raw data ----
    raw_df <- read_parquet(raw_file) |> clean_names()
    raw_n  <- nrow(raw_df)

    # (A) Remove unwanted admin columns
    df1 <- raw_df |>
      select(-c(
        dispatching_base_num,
        originating_base_num,
        shared_request_flag,
        shared_match_flag,
        access_a_ride_flag,
        wav_request_flag,
        wav_match_flag
      ))
    drop_admin <- raw_n - nrow(df1)

    # (B) Count rows with negative values (before真正刪除)
    drop_fare       <- sum(df1$base_passenger_fare < 0, na.rm = TRUE)
    drop_tolls      <- sum(df1$tolls < 0, na.rm = TRUE)
    drop_bcf        <- sum(df1$bcf < 0, na.rm = TRUE)
    drop_sales_tax  <- sum(df1$sales_tax < 0, na.rm = TRUE)
    drop_surcharge  <- sum(df1$congestion_surcharge < 0, na.rm = TRUE)
    drop_airport    <- sum(df1$airport_fee < 0, na.rm = TRUE)
    drop_tips       <- sum(df1$tips < 0, na.rm = TRUE)
    drop_driver_pay <- sum(df1$driver_pay < 0, na.rm = TRUE)

    # (C) Filter negative values (實際刪除)
    df_clean <- df1 |>
      filter(
        base_passenger_fare >= 0,
        tolls                >= 0,
        bcf                  >= 0,
        sales_tax            >= 0,
        congestion_surcharge >= 0,
        airport_fee          >= 0,
        tips                 >= 0,
        driver_pay           >= 0
      ) |>
      as.data.frame()

    final_n <- nrow(df_clean)

    # (D) Save per-month deletion log (in memory only)
    
    total_deleted <- raw_n - final_n
    delete_log[[mt]] <- data.frame(
      month           = mt,
      raw_n           = raw_n,
      after_admin     = nrow(df1),
      final_n         = final_n,
      drop_admin      = drop_admin,
      drop_fare       = drop_fare,
      drop_tolls      = drop_tolls,
      drop_bcf        = drop_bcf,
      drop_sales_tax  = drop_sales_tax,
      drop_surcharge  = drop_surcharge,
      drop_airport    = drop_airport,
      drop_tips       = drop_tips,
      drop_driver_pay = drop_driver_pay,
      # 新增兩個欄位：
      total_deleted   = total_deleted,
      delete_ratio    = total_deleted / raw_n   # 刪除比例（0~1）
      # 如果你想要百分比，可以用： delete_pct = 100 * total_deleted / raw_n
    )
    # (E) Accumulate cleaned data for this group
    combined_list[[idx]] <- df_clean
    idx <- idx + 1L

    rm(raw_df, df1, df_clean); gc()
  }

  # 如果這個 group 沒有任何月被成功讀取 & 清理，就跳過
  if (length(combined_list) == 0) {
    warning(sprintf("No valid months processed for group %s. Skipping group combine.", g))
    next
  }

  # ---- Bind all cleaned months in this group ----
  combined_df <- dplyr::bind_rows(combined_list)

  # ---- Save combined .rds for this group ----
  combined_rds_path <- file.path(
    output_dir,
    sprintf("hvfhv_cleaned_%s_combined.rds", g)
  )
  saveRDS(combined_df, combined_rds_path, compress = "xz")

  # ---- Compute size of corresponding raw parquet files ----
  raw_files <- file.path(
    data_dir,
    paste0(month_tags, ".parquet")
  )
  raw_files_exist <- raw_files[file.exists(raw_files)]
  raw_sizes <- file.info(raw_files_exist)$size
  raw_total_size <- sum(raw_sizes, na.rm = TRUE)

  # ---- Size of combined .rds ----
  combined_size <- file.info(combined_rds_path)$size

  cat("  ✔ Combined .rds saved to:\n")
  cat("    ", combined_rds_path, "\n")
  cat("  Raw parquet total size:   ", pretty_size(raw_total_size), "\n")
  cat("  Combined .rds file size:  ", pretty_size(combined_size), "\n")
  cat("  Combined rows (nrow):     ", nrow(combined_df), "\n")

  rm(combined_df, combined_list); gc()
}

# =========================================================
# 7. Print deletion summary (不輸出檔案，只印出來)
# =========================================================
if (length(delete_log) > 0) {
  delete_summary <- bind_rows(delete_log) |> arrange(month)
  cat("\n===== Deletion summary by month (preview) =====\n")
  print(delete_summary)
} else {
  cat("\n(No months were processed, no deletion summary.)\n")
}
```
