---
title: "Air quality Synthetic Control"
author: "Auto-converted"
output: html_document
date: "`r format(Sys.time(), '%Y-%m-%d')`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Background

- **Author**: `<Ju-Chien, Yao>`
- **Created At**: `<2025/11/03>`
- **Research Motivation and Context (why are we interested in the findings?)：** We want to see how the air quality changes in different regions after the implementation of congestion fee.
- **Main Findings and Takeaways：** The regional effect is not apparent. Maybe some control variable should be added.
- **Future Direciton：** Add temperature, precipitation and other climate variables; Apply DID or GSC.

```{r}
# Load packages here
remove(list = ls()) 
library(sf)
library(tmap)
library(dplyr)
library(tidyr)
library(arrow)
library(ggplot2)
library(lubridate)
library(tidysynth)
library(stringr)
library(fixest)
```

### 讀資料

```{r}
# Load input data here and please finish all the data manipulation here.
# Assuming your dataframe is named 'control'

## Reading Data
climate = read.csv("C:/114-1_Autumn/Data_science_and_social_inquiry/data/air_quality/processed_pm2.5_AQI.csv") %>% 
  dplyr::select(c(-X)) %>%
  mutate(Date = as.Date(Date, format = "%m/%d/%Y"))

## Produce weekly data
climate_weekly <- climate %>%
  # Create a "week" variable from the datetime column
  mutate(week = floor_date(Date, "week")) %>%
  # Group by week and region (if multiple locations)
  group_by(region, week) %>%
  # Compute weekly means
  summarise(
    PM2.5_avg = mean(`PM2.5`, na.rm = TRUE),
    AQI_avg  = mean(AQI, na.rm = TRUE),
    .groups = "drop"
  )

# Finish this block by printing the first ten observations of the data.

## Take the main data (the read-in-to-use one) as example
head(climate_weekly, 10)

# Note:
# - You may only read data from /data/processed.
# - Files in /data/processed should already be cleaned and prepared for analysis.
# - Beyond simple filtering of observations or generating a small number of variables,
#   further data manipulation is not allowed. If more extensive changes are needed,
#   update the source data instead.
```

```{r}
# Before conducting the analysis, report summary statistics for all variables 
# that will be used in this notebook:
#   - For numeric variables: mean, min, 25th percentile, median, 75th percentile, 
#     max, standard deviation, and number of observations.

# The number of observations
nrow(climate_weekly)

# For PM2.5
summary(climate_weekly$PM2.5_avg)
sd(climate_weekly$PM2.5_avg)

# For AQI
summary(climate_weekly$AQI_avg)
sd(climate_weekly$AQI_avg)

#   - For categorical variables: number of observations and the counts/percentages 
#     of the ten most frequent categories.
# Conclude this block with the complete summary statistics.
```

## The actual analysis starts below

### Ensure data availability

```{r}
# Define your cutoff
cutoff_date <- as.Date("2025-03-23")

# Filter the data
scm_data_filtered <- climate_weekly %>%
  filter(week <= cutoff_date)

# CHECK: Run this line to see if the counts are now identical
table(scm_data_filtered$region)
```

### 讀進氣候控制變數

這裡的氣候控制變數資料來自sensoto網站，是一個感測器的彙整資料庫。`control` 是中央公園的資料，包含降水、氣溫跟風速，在政策範圍外；`treatment` 是則位於紐約越戰紀念碑旁，包含氣溫、風速，在政策範圍內。

```{r}
control = read.csv("C:/114-1_Autumn/Data_science_and_social_inquiry/data/new-weather-data/measurements.csv") %>%
  rename_with(~ case_when(
    .x == "begin" ~ "start_date",
    .x == "end" ~ "end_date",
    # Use str_extract to grab the core variable name (e.g., LIQUID_PRECIPITATION)
    # Then use str_extract again to grab the value type (e.g., _v, _lo, _hi, _c)
    str_detect(.x, "PRECIPITATION") ~ paste0("precip_", str_extract(.x, "_v|_lo|_hi|_c$") %>% str_remove("_")),
    str_detect(.x, "TEMPERATURE") ~ paste0("temp_", str_extract(.x, "_v|_lo|_hi|_c$") %>% str_remove("_")),
    str_detect(.x, "WIND_SPEED_RATE") ~ paste0("wind_", str_extract(.x, "_v|_lo|_hi|_c$") %>% str_remove("_")),
    TRUE ~ .x # Keep other names if they exist
  ))

control = cbind(control, week = scm_data_filtered$week) 

treatment = read.csv("C:/114-1_Autumn/Data_science_and_social_inquiry/data/new-weather-treatment-data/measurements.csv") %>%
  rename_with(~ case_when(
    .x == "begin" ~ "start_date",
    .x == "end" ~ "end_date",
    # Use str_extract to grab the core variable name (e.g., LIQUID_PRECIPITATION)
    # Then use str_extract again to grab the value type (e.g., _v, _lo, _hi, _c)
    str_detect(.x, "PRECIPITATION") ~ paste0("precip_", str_extract(.x, "_v|_lo|_hi|_c$") %>% str_remove("_")),
    str_detect(.x, "TEMPERATURE") ~ paste0("temp_", str_extract(.x, "_v|_lo|_hi|_c$") %>% str_remove("_")),
    str_detect(.x, "WIND_SPEED_RATE") ~ paste0("wind_", str_extract(.x, "_v|_lo|_hi|_c$") %>% str_remove("_")),
    TRUE ~ .x # Keep other names if they exist
  ))
```

### 初始 SCM

```{r}
# Policy start time
intervention_date <- as.Date("2025-01-05")

# New start date based on filtered data
start_date <- min(scm_data_filtered$week)

pm25_out <- scm_data_filtered %>%
  
  # Initialize
  synthetic_control(
    outcome = PM2.5_avg,
    unit = region,
    time = week,
    i_unit = "East Village", 
    i_time = intervention_date,
    generate_placebos = TRUE 
  ) %>%
  
  # Generate Predictors
  generate_predictor(
    time_window = c(start_date, intervention_date - 7),
    avg_pm25 = mean(PM2.5_avg, na.rm = TRUE)
  ) %>%
  
  # Generate Weights
  generate_weights(optimization_window = c(start_date, intervention_date - 7)) %>%
  
  # Generate Control
  generate_control()
```



```{r}
# Plot Trends
pm25_out %>% plot_trends() + 
  labs(title = "Synthetic Control (Data capped at Mar 23)",
       subtitle = "East Village vs. Synthetic Control",
       x = "time by week", 
       y = "average PM2.5 concentration (μg/m³)")
```

```{r}
# Plot 2: The Gap (Treatment Effect)
pm25_out %>% plot_differences() +
  labs(title = "Gap between East Village and Synthetic Control",
       subtitle = "Negative values indicate East Village air is cleaner than expected")
```

### Placebo Test

將其他三個控制組地區也重複做上面的操作，如果placebo gap的趨勢跟政策範圍內的差異不同，政策效果或許有效。

```{r}
# Plot 3: Placebo Test (Significance)
# This checks if the effect in East Village is larger than if we 
# randomly assigned the intervention to the other regions.
pm25_out %>% plot_placebos() +
  labs(title = "Placebo Test",
       subtitle = "Is the East Village deviation unique?")
```

單純用SCM的結果，可以看到結果非常雜亂，可以說政策的效果並不顯著。

```{r}
# 1. Ensure dates are proper and create the 'week' variable
treatment_weekly <- treatment %>%
  select(start_date, end_date, matches("_v$")) %>%
  mutate(
    date = as.Date(end_date), 
    week = floor_date(date, "week")
  ) %>%
  
  # 2. Aggregate to Weekly: Mean for Temp/Wind
  group_by(week) %>%
  summarise(
    temp_treat_v = mean(temp_v, na.rm = TRUE),
    wind_treat_v = mean(wind_v, na.rm = TRUE),
    # Note: Precipitation is missing in 'treatment' data; we must handle this later.
    .groups = "drop"
  ) %>%
  
  # Add region identifier
  mutate(region = "East Village")
```

```{r}
# Re-load and clean Central Park weekly data (assuming it's available)
control_weekly_full <- control %>%
  select(start_date, end_date, matches("_v$")) %>%
  mutate(
    date = as.Date(end_date), 
    week = floor_date(date, "week")
  ) %>%
  group_by(week) %>%
  summarise(
    temp_avg_c = mean(temp_v, na.rm = TRUE),
    precip_total_mm = sum(precip_v, na.rm = TRUE),
    wind_avg_m_s = mean(wind_v, na.rm = TRUE),
    .groups = "drop"
  )

# Start with filtered air quality data and join Central Park data (for all regions)
scm_data_merged <- scm_data_filtered %>%
  left_join(control_weekly_full, by = "week") %>%
  
  # Add the specific East Village data (where region matches)
  left_join(treatment_weekly, by = c("region", "week")) %>%
  
  # Create final covariate columns, prioritizing East Village data where available
  mutate(
    temp_final = coalesce(temp_treat_v, temp_avg_c),
    wind_final = coalesce(wind_treat_v, wind_avg_m_s),
    precip_final = precip_total_mm # Using Central Park precip for all regions
  ) %>%
  select(-temp_treat_v, -wind_treat_v, -temp_avg_c, -wind_avg_m_s, -precip_total_mm) %>%
  
  # Impute remaining NA values for the predictors
  group_by(region) %>%
  fill(temp_final, wind_final, precip_final, .direction = "downup") %>%
  ungroup()

# Check: The East Village rows should have different climate values than the controls
head(scm_data_merged)
```

### SDID (Synthetic Difference in Difference)

#### 權重的建立

```{r}
# 提取 SCM 權重 (只保留權重 > 0 的地區)
scm_weights <- pm25_out %>%
  tidysynth::grab_unit_weights() %>%
  rename(region = unit) %>% # 將 unit 欄位名稱改為 region 以利合併
  filter(weight > 0)

print("提取到的控制組權重:")
print(scm_weights)
```

#### 建構時間序列

```{r}
# 1. 隔離控制組原始數據
control_data_raw <- scm_data_merged %>% 
    filter(region != "East Village")

# 2. 結合權重並計算加權平均
weighted_control_data <- control_data_raw %>%
    inner_join(scm_weights, by = "region") %>%
    group_by(week) %>%
    summarise(
        # 加權平均 PM2.5 (核心步驟)
        PM2.5_avg = sum(PM2.5_avg * weight, na.rm = TRUE),
        
        # 氣候變數：由於控制組氣候數據相同，這裡取平均即可
        temp_final = mean(temp_final, na.rm = TRUE), 
        wind_final = mean(wind_final, na.rm = TRUE),
        
        region = "Weighted_Control",
        .groups = "drop"
    )

# 3. 結合東村數據和加權控制組數據
did_weighted_data <- scm_data_merged %>%
    filter(region == "East Village") %>%
    bind_rows(weighted_control_data) %>%
    
    # 4. 建立 DID 虛擬變數
    mutate(
        treat = as.numeric(region == "East Village"),
        post = as.numeric(week >= as.Date("2025-01-05")),
        did_term = treat * post # 交互作用項：政策效果
    )
```

#### regression

$$
PM2.5_{i,t} = \alpha + \tau_{1} \cdot DID_{it} + \mu_{i} + \lambda_{t} + \epsilon_{it}
$$

```{r}
# Model 1: 基礎固定效應模型
model_base_fe <- feols(
  PM2.5_avg ~ did_term | region + week,
  data = did_weighted_data
)
```

$$
PM2.5_{i,t} = \alpha + \tau_{2} \cdot DID_{it} + \gamma_{1} \cdot Temp_{it} + \gamma_{2} \cdot Wind_{it} + \mu_{i} + \lambda_{t} + \epsilon_{it} 
$$

```{r}
library(fixest)
library(stargazer)

# Model 1
base_sdid <- feols(
  PM2.5_avg ~ did_term | region + week,
  data = did_weighted_data
)

# Model 2
sdid_covariates <- feols(
  PM2.5_avg ~ did_term + temp_final + wind_final | region + week,
  data = did_weighted_data
)

# Stargazer 輸出 LaTeX
stargazer(
  base_sdid, sdid_covariates,
  type = "latex",
  title = "Difference-in-Differences with Fixed Effects",
  dep.var.labels = "PM2.5 Average",
  column.labels = c("Baseline FE Model", "FE + Climate Covariates"),
  covariate.labels = c(
    "DID (政策效果)",
    "Temperature",
    "Wind Speed"
  ),
  add.lines = list(
    c("Region FE", "Yes", "Yes"),
    c("Week FE", "Yes", "Yes")
  ),
  keep.stat = c("n", "rsq", "aic"),
  no.space = TRUE,
  label = "tab:sdid_results"
)

```


```{r}
# 輸出並排比較結果
etable(base_sdid, sdid_covariates,
       fitstat = c('n', 'r2', 'aic'),
       dict = c(did_term = "DID (政策效果)"),
       # 輸出時 fixest 會提示哪些變數被移除了
       tex = FALSE
)
```

did_term 係數為 -0.7222* (P值極小)，表示在控制了地區和時間固定效應以及氣候變數後，擁堵費政策導致 East Village 的 PM2.5 顯著下降了約 0.7222 µg/m³。

temp_final 和 wind_final 係數也顯著，表明氣候衝擊確實與 PM2.5 相關。

```{r}
library(modelsummary)
# (假設 base_sdid 和 sdid_covariates 模型已在環境中)

# 定義模型列表
models <- list(
  "Model 1: Baseline FE" = base_sdid,
  "Model 2: FE + Climate" = sdid_covariates
)

# 使用 modelsummary 輸出為 LaTeX
modelsummary(
  models,
  output = "latex", # 輸出格式
  title = "SDID 模型逐步結果比較",
  # 調整統計數據和標籤
  stars = c('*' = .1, '**' = .05, '***' = .01), # 設定星號顯著性
  gof_map = c("nobs", "r.squared", "aic"), # 選擇要顯示的統計量
  coef_map = c(
    "did_term" = "DID (政策效果)",
    "temp_final" = "溫度",
    "wind_final" = "風速"
  ),
  # 調整固定效應的顯示（fixest 會自動處理）
  add_rows = data.frame(
    term = c("地區固定效應 (Region FE)", "時間固定效應 (Week FE)"),
    # modelsummary 會自動檢測 fixest 的 FE
    "(1)" = c("Yes", "Yes"),
    "(2)" = c("Yes", "Yes")
  ),
  notes = "Model 2 的氣候變數因共線性被移除。標準誤已進行地區集束 (Region Clustered)。"
)
```

