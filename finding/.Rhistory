climate_biweekly <- climate %>%
mutate(biweek = floor_date(Date - days(7 * (week(Date) %% 2)), "week")) %>%
group_by(region, biweek) %>%
summarise(
PM25_avg = mean(`PM2.5`, na.rm = TRUE),
AQI_avg  = mean(AQI, na.rm = TRUE),
.groups = "drop"
)
# Finish this block by printing the first ten observations of the data.
## Take the main data (the read-in-to-use one) as example
head(climate, 10)
# Note:
# - You may only read data from /data/processed.
# - Files in /data/processed should already be cleaned and prepared for analysis.
# - Beyond simple filtering of observations or generating a small number of variables,
#   further data manipulation is not allowed. If more extensive changes are needed,
#   update the source data instead.
# Before conducting the analysis, report summary statistics for all variables
# that will be used in this notebook:
#   - For numeric variables: mean, min, 25th percentile, median, 75th percentile,
#     max, standard deviation, and number of observations.
# The number of observations
nrow(climate)
# For PM2.5
summary(climate$PM2.5)
sd(climate$PM2.5)
# For AQI
summary(climate$AQI)
sd(climate$AQI)
#   - For categorical variables: number of observations and the counts/percentages
#     of the ten most frequent categories.
# Conclude this block with the complete summary statistics.
ggplot(climate_biweekly, aes(x = biweek, y = PM25_avg, color = region)) +
geom_line(linewidth = 0.9) +
geom_vline(xintercept = as.POSIXct("2025-01-05"),
linetype = "dashed",
color = "black",
linewidth = 1) +
labs(
title = "Biweekly Average PM2.5 by Region",
x = "Biweek (starting date)",
y = "PM2.5 (µg/m³)"
)
ggplot(climate_biweekly, aes(x = biweek, y = AQI_avg, color = region)) +
geom_line(linewidth = 0.9) +
geom_vline(xintercept = as.POSIXct("2025-01-05"),
linetype = "dashed",
color = "black",
linewidth = 1) +
labs(
title = "Biweekly Average AQI by Region",
x = "Biweek (starting date)",
y = "AQI"
)
View(climate)
distinct(climate$region)
unique(climate$region)
View(climate)
# Load packages here
install.packages("tidysynth")
library(tidysynth)
class(scm_data)
class(climate_weekly)
# Ensure the data is a standard data frame (tibbles work, but ungrouping helps)
scm_data <- climate_weekly %>%
ungroup() %>%
# Make sure region is a character or factor
mutate(region = as.character(region))
class(scm_data)
# Ensure the data is a standard data frame (tibbles work, but ungrouping helps)
scm_data <- climate_weekly %>%
ungroup() %>%
# Make sure region is a character or factor
mutate(region = as.character(region))
class(scm_data)
# Define key dates
intervention_date <- as.Date("2025-01-05")
# We need the start date of your data to define the pre-intervention window
start_date <- min(scm_data$week)
# Initialize the Synthetic Control Object
pm25_out <- scm_data %>%
# 1. Initialize: Setup the panel structure
synthetic_control(
outcome = PM2.5_avg,      # The variable we want to analyze
unit = region,            # The column identifying regions
time = week,              # The time variable
i_unit = "East Village",  # The Treatment Unit
i_time = intervention_date, # When the congestion fee started
generate_placebos = TRUE  # Important for inference (checking significance)
) %>%
# 2. Generate Predictors:
# Since we don't have weather data yet, we use the average PM2.5
# of the pre-intervention period as the main predictor.
# We can also add specific time points as predictors to improve fit.
generate_predictor(
time_window = c(start_date, intervention_date - 7),
avg_pm25 = mean(PM2.5_avg, na.rm = TRUE)
) %>%
# 3. Generate Weights: Calculates how much each control region contributes
generate_weights(optimization_window = c(start_date, intervention_date - 7)) %>%
# 4. Generate the Synthetic Control
generate_control()
View(scm_data)
# Define your cutoff
cutoff_date <- as.Date("2025-03-23")
# Filter the data
scm_data_filtered <- climate_weekly %>%
filter(week <= cutoff_date)
# CHECK: Run this line to see if the counts are now identical
table(scm_data_filtered$region)
# Update the intervention date if needed, otherwise keep as is
intervention_date <- as.Date("2025-01-05")
# New start date based on filtered data
start_date <- min(scm_data_filtered$week)
pm25_out <- scm_data_filtered %>%
# Initialize
synthetic_control(
outcome = PM2.5_avg,
unit = region,
time = week,
i_unit = "East Village",
i_time = intervention_date,
generate_placebos = TRUE
) %>%
# Generate Predictors
generate_predictor(
time_window = c(start_date, intervention_date - 7),
avg_pm25 = mean(PM2.5_avg, na.rm = TRUE)
) %>%
# Generate Weights
generate_weights(optimization_window = c(start_date, intervention_date - 7)) %>%
# Generate Control
generate_control()
# Plot Trends
pm25_out %>% plot_trends() +
labs(title = "Synthetic Control (Data capped at Mar 23)",
subtitle = "East Village vs. Synthetic Control")
View(pm25_out)
View(pm25_out[[4]][[1]])
View(pm25_out[[7]][[3]])
View(pm25_out[[7]][[1]])
View(pm25_out[[7]][[2]])
View(pm25_out[[8]][[1]])
View(pm25_out[[11]][[1]])
# Plot 2: The Gap (Treatment Effect)
pm25_out %>% plot_differences() +
labs(title = "Gap between East Village and Synthetic Control",
subtitle = "Negative values indicate East Village air is cleaner than expected")
# Plot 3: Placebo Test (Significance)
# This checks if the effect in East Village is larger than if we
# randomly assigned the intervention to the other regions.
pm25_out %>% plot_placebos() +
labs(title = "Placebo Test",
subtitle = "Is the East Village deviation unique?")
unique(scm_data_filtered$region)
library(sf)
library(tmap)
library(dplyr)
library(tidyr)
library(arrow)
# Reading Data
nyc_shp = st_read("C:/114-1_Autumn/Data_science_and_social_inquiry/data/nyc_map/taxi_zones.shp")
ny_air = read.csv("C:/114-1_Autumn/Data_science_and_social_inquiry/data/air_quality/ad_viz_plotval_data.csv")
# Selecting Manhattan
mht_shp = nyc_shp %>%
filter(borough == "Manhattan")
tm_shape(mht_shp) +
tm_polygons()
ny_air_sf <- ny_air %>%
filter(!is.na(Site.Latitude) & !is.na(Site.Longitude)) %>%
st_as_sf(coords = c("Site.Longitude", "Site.Latitude"), crs = 4326)
# Adjust the coordinate of shp
mht_shp = st_transform(mht_shp, st_crs(ny_air_sf))
st_crs(mht_shp)
# 使用 tmap 繪圖
tm_shape(mht_shp) +
tm_polygons(col = "lightgray", border.col = "black") +  # 底圖 polygon
tm_shape(ny_air_sf) +
tm_dots(size = 0.5, fill = "red") +                     # 測站點
tm_layout(title = "Manhattan Air Quality / Weather Stations", frame = TRUE)
sites_in_mht = st_intersection(ny_air_sf, mht_shp)
tm_shape(mht_shp) +
tm_polygons(col = "lightgray", border.col = "black") +  # 底圖 polygon
tm_shape(sites_in_mht) +
tm_dots(size = 0.5, fill = "red") +                     # 測站點
tm_layout(title = "Manhattan Air Quality / Weather Stations", frame = TRUE)
View(sites_in_mht)
tm_shape(mht_shp) +
tm_polygons(col = "lightgray", border.col = "black") +     # Manhattan polygons
tm_shape(sites_in_mht) +
tm_dots(size = 0.5, fill = "red") +                        # Weather stations
tm_text("zones", size = 0.6, ymod = -0.0005) +             # <-- Add labels here
tm_layout(title = "Manhattan Air Quality / Weather Stations",
frame = TRUE)
tm_shape(mht_shp) +
tm_polygons(col = "lightgray", border.col = "black") +     # Manhattan polygons
tm_shape(sites_in_mht) +
tm_dots(size = 0.5, fill = "red") +                        # Weather stations
tm_text(zones, size = 0.6, ymod = -0.0005) +             # <-- Add labels here
tm_layout(title = "Manhattan Air Quality / Weather Stations",
frame = TRUE)
tm_shape(mht_shp) +
tm_polygons(col = "lightgray", border.col = "black") +     # Manhattan polygons
tm_shape(sites_in_mht) +
tm_dots(size = 0.5, fill = "red") +                        # Weather stations
tm_text("zone", size = 0.6, ymod = -0.0005) +             # <-- Add labels here
tm_layout(title = "Manhattan Air Quality / Weather Stations",
frame = TRUE)
tm_shape(mht_shp) +
tm_polygons(col = "lightgray", border.col = "black") +     # Manhattan polygons
tm_shape(sites_in_mht) +
tm_dots(size = 0.5, fill = "red") +                        # Weather stations
tm_text("zone", size = 0.6, ymod = -0.05) +             # <-- Add labels here
tm_layout(title = "Manhattan Air Quality / Weather Stations",
frame = TRUE)
tm_shape(mht_shp) +
tm_polygons(col = "lightgray", border.col = "black") +     # Manhattan polygons
tm_shape(sites_in_mht) +
tm_dots(size = 0.5, fill = "red") +                        # Weather stations
tm_text("zone", size = 0.6, ymod = -0.5) +             # <-- Add labels here
tm_layout(title = "Manhattan Air Quality / Weather Stations",
frame = TRUE)
tm_shape(mht_shp) +
tm_polygons(col = "lightgray", border.col = "black") +     # Manhattan polygons
tm_shape(sites_in_mht) +
tm_dots(size = 0.5, fill = "red") +                        # Weather stations
tm_text("zone", size = 0.6, xmod = - 0.5, ymod = -0.5) +             # <-- Add labels here
tm_layout(title = "Manhattan Air Quality / Weather Stations",
frame = TRUE)
tm_shape(mht_shp) +
tm_polygons(col = "lightgray", border.col = "black") +     # Manhattan polygons
tm_shape(sites_in_mht) +
tm_dots(size = 0.5, fill = "red") +                        # Weather stations
tm_text("zone", size = 0.6, xmod = -1, ymod = -0.5) +             # <-- Add labels here
tm_layout(title = "Manhattan Air Quality / Weather Stations",
frame = TRUE)
install.packages("rnoaa")
install.packages("installr")
library(installr)
updateR()
keep_install_file=TRUE
updateR()
updateR()
# Reading Data
# Replace 'YOUR_NOAA_API_KEY' with the actual key you received via email.
options(noaakey = "copQSTyRJcwglGAJMLmiARBMhyRWFWiV")
library(rnoaa)
install.packages("rnoaa")
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
# Load packages here
remove(list = ls())
library(sf)
library(tmap)
library(dplyr)
library(tidyr)
library(arrow)
library(ggplot2)
library(lubridate)
library(tidysynth)
library(stringr)
# Load input data here and please finish all the data manipulation here.
# Assuming your dataframe is named 'control'
## Reading Data
climate = read.csv("C:/114-1_Autumn/Data_science_and_social_inquiry/data/air_quality/processed_pm2.5_AQI.csv") %>%
select(c(-X)) %>%
mutate(Date = as.Date(Date, format = "%m/%d/%Y"))
## Produce weekly data
climate_weekly <- climate %>%
# Create a "week" variable from the datetime column
mutate(week = floor_date(Date, "week")) %>%
# Group by week and region (if multiple locations)
group_by(region, week) %>%
# Compute weekly means
summarise(
PM2.5_avg = mean(`PM2.5`, na.rm = TRUE),
AQI_avg  = mean(AQI, na.rm = TRUE),
.groups = "drop"
)
# Finish this block by printing the first ten observations of the data.
## Take the main data (the read-in-to-use one) as example
head(climate_weekly, 10)
# Note:
# - You may only read data from /data/processed.
# - Files in /data/processed should already be cleaned and prepared for analysis.
# - Beyond simple filtering of observations or generating a small number of variables,
#   further data manipulation is not allowed. If more extensive changes are needed,
#   update the source data instead.
# Before conducting the analysis, report summary statistics for all variables
# that will be used in this notebook:
#   - For numeric variables: mean, min, 25th percentile, median, 75th percentile,
#     max, standard deviation, and number of observations.
# The number of observations
nrow(climate_weekly)
# For PM2.5
summary(climate_weekly$PM2.5_avg)
sd(climate_weekly$PM2.5_avg)
# For AQI
summary(climate_weekly$AQI_avg)
sd(climate_weekly$AQI_avg)
#   - For categorical variables: number of observations and the counts/percentages
#     of the ten most frequent categories.
# Conclude this block with the complete summary statistics.
# Define your cutoff
cutoff_date <- as.Date("2025-03-23")
# Filter the data
scm_data_filtered <- climate_weekly %>%
filter(week <= cutoff_date)
# CHECK: Run this line to see if the counts are now identical
table(scm_data_filtered$region)
control = read.csv("C:/114-1_Autumn/Data_science_and_social_inquiry/data/new-weather-data/measurements.csv") %>%
rename_with(~ case_when(
.x == "begin" ~ "start_date",
.x == "end" ~ "end_date",
# Use str_extract to grab the core variable name (e.g., LIQUID_PRECIPITATION)
# Then use str_extract again to grab the value type (e.g., _v, _lo, _hi, _c)
str_detect(.x, "PRECIPITATION") ~ paste0("precip_", str_extract(.x, "_v|_lo|_hi|_c$") %>% str_remove("_")),
str_detect(.x, "TEMPERATURE") ~ paste0("temp_", str_extract(.x, "_v|_lo|_hi|_c$") %>% str_remove("_")),
str_detect(.x, "WIND_SPEED_RATE") ~ paste0("wind_", str_extract(.x, "_v|_lo|_hi|_c$") %>% str_remove("_")),
TRUE ~ .x # Keep other names if they exist
))
control = cbind(control, week = scm_data_filtered$week)
treatment = read.csv("C:/114-1_Autumn/Data_science_and_social_inquiry/data/new-weather-treatment-data/measurements.csv") %>%
rename_with(~ case_when(
.x == "begin" ~ "start_date",
.x == "end" ~ "end_date",
# Use str_extract to grab the core variable name (e.g., LIQUID_PRECIPITATION)
# Then use str_extract again to grab the value type (e.g., _v, _lo, _hi, _c)
str_detect(.x, "PRECIPITATION") ~ paste0("precip_", str_extract(.x, "_v|_lo|_hi|_c$") %>% str_remove("_")),
str_detect(.x, "TEMPERATURE") ~ paste0("temp_", str_extract(.x, "_v|_lo|_hi|_c$") %>% str_remove("_")),
str_detect(.x, "WIND_SPEED_RATE") ~ paste0("wind_", str_extract(.x, "_v|_lo|_hi|_c$") %>% str_remove("_")),
TRUE ~ .x # Keep other names if they exist
))
# Policy start time
intervention_date <- as.Date("2025-01-05")
# New start date based on filtered data
start_date <- min(scm_data_filtered$week)
pm25_out <- scm_data_filtered %>%
# Initialize
synthetic_control(
outcome = PM2.5_avg,
unit = region,
time = week,
i_unit = "East Village",
i_time = intervention_date,
generate_placebos = TRUE
) %>%
# Generate Predictors
generate_predictor(
time_window = c(start_date, intervention_date - 7),
avg_pm25 = mean(PM2.5_avg, na.rm = TRUE)
) %>%
# Generate Weights
generate_weights(optimization_window = c(start_date, intervention_date - 7)) %>%
# Generate Control
generate_control()
# Plot Trends
pm25_out %>% plot_trends() +
labs(title = "Synthetic Control (Data capped at Mar 23)",
subtitle = "East Village vs. Synthetic Control")
# Plot 2: The Gap (Treatment Effect)
pm25_out %>% plot_differences() +
labs(title = "Gap between East Village and Synthetic Control",
subtitle = "Negative values indicate East Village air is cleaner than expected")
# Plot 3: Placebo Test (Significance)
# This checks if the effect in East Village is larger than if we
# randomly assigned the intervention to the other regions.
pm25_out %>% plot_placebos() +
labs(title = "Placebo Test",
subtitle = "Is the East Village deviation unique?")
# 1. Ensure dates are proper and create the 'week' variable
treatment_weekly <- treatment %>%
select(start_date, end_date, matches("_v$")) %>%
mutate(
date = as.Date(end_date),
week = floor_date(date, "week")
) %>%
# 2. Aggregate to Weekly: Mean for Temp/Wind
group_by(week) %>%
summarise(
temp_treat_v = mean(temp_v, na.rm = TRUE),
wind_treat_v = mean(wind_v, na.rm = TRUE),
# Note: Precipitation is missing in 'treatment' data; we must handle this later.
.groups = "drop"
) %>%
# Add region identifier
mutate(region = "East Village")
# Re-load and clean Central Park weekly data (assuming it's available)
control_weekly_full <- control %>%
select(start_date, end_date, matches("_v$")) %>%
mutate(
date = as.Date(end_date),
week = floor_date(date, "week")
) %>%
group_by(week) %>%
summarise(
temp_avg_c = mean(temp_v, na.rm = TRUE),
precip_total_mm = sum(precip_v, na.rm = TRUE),
wind_avg_m_s = mean(wind_v, na.rm = TRUE),
.groups = "drop"
)
# Start with filtered air quality data and join Central Park data (for all regions)
scm_data_merged <- scm_data_filtered %>%
left_join(control_weekly_full, by = "week") %>%
# Add the specific East Village data (where region matches)
left_join(treatment_weekly, by = c("region", "week")) %>%
# Create final covariate columns, prioritizing East Village data where available
mutate(
temp_final = coalesce(temp_treat_v, temp_avg_c),
wind_final = coalesce(wind_treat_v, wind_avg_m_s),
precip_final = precip_total_mm # Using Central Park precip for all regions
) %>%
select(-temp_treat_v, -wind_treat_v, -temp_avg_c, -wind_avg_m_s, -precip_total_mm) %>%
# Impute remaining NA values for the predictors
group_by(region) %>%
fill(temp_final, wind_final, precip_final, .direction = "downup") %>%
ungroup()
# Check: The East Village rows should have different climate values than the controls
head(scm_data_merged)
# 提取 SCM 權重 (只保留權重 > 0 的地區)
scm_weights <- pm25_out %>%
tidysynth::grab_unit_weights() %>%
rename(region = unit) %>% # 將 unit 欄位名稱改為 region 以利合併
filter(weight > 0)
print("提取到的控制組權重:")
print(scm_weights)
# 1. 隔離控制組原始數據
control_data_raw <- scm_data_merged %>%
filter(region != "East Village")
# 2. 結合權重並計算加權平均
weighted_control_data <- control_data_raw %>%
inner_join(scm_weights, by = "region") %>%
group_by(week) %>%
summarise(
# 加權平均 PM2.5 (核心步驟)
PM2.5_avg = sum(PM2.5_avg * weight, na.rm = TRUE),
# 氣候變數：由於控制組氣候數據相同，這裡取平均即可
temp_final = mean(temp_final, na.rm = TRUE),
wind_final = mean(wind_final, na.rm = TRUE),
region = "Weighted_Control",
.groups = "drop"
)
# 3. 結合東村數據和加權控制組數據
did_weighted_data <- scm_data_merged %>%
filter(region == "East Village") %>%
bind_rows(weighted_control_data) %>%
# 4. 建立 DID 虛擬變數
mutate(
treat = as.numeric(region == "East Village"),
post = as.numeric(week >= as.Date("2025-01-05")),
did_term = treat * post # 交互作用項：政策效果
)
library(fixest)
# SDID 模型: 包含地區固定效應 (region) 和時間固定效應 (week)
# 並且控制氣候變數
sdid_model <- feols(
PM2.5_avg ~ did_term +
temp_final + wind_final | region + week,
data = did_weighted_data
)
# 輸出詳細結果
etable(sdid_model, fitstat = c('n', 'r2', 'aic'))
library(ggplot2)
library(dplyr)
library(lubridate)
# Define the intervention date (from your previous steps)
intervention_date <- as.Date("2025-01-05")
# 1. 繪製趨勢圖
sdid_trends_plot <- did_weighted_data %>%
ggplot(aes(x = week, y = PM2.5_avg, color = region)) +
geom_line(linewidth = 1) +
# 政策介入時間線
geom_vline(xintercept = as.numeric(intervention_date), linetype = "dashed", color = "red") +
labs(
title = "SDID 趨勢圖：政策對 PM2.5 的影響",
subtitle = "東村 vs. SCM 加權控制組",
y = "PM2.5 平均濃度 (µg/m³)",
x = "週",
color = "地區"
) +
scale_color_manual(values = c("East Village" = "#0072B2", "Weighted_Control" = "#D55E00")) + # 設定顏色
theme_minimal() +
theme(legend.position = "bottom", plot.title = element_text(hjust = 0.5))
print(sdid_trends_plot)
# 1. 計算差距 (Gap = 實際值 - 反事實)
sdid_gap_data <- did_weighted_data %>%
select(week, region, PM2.5_avg) %>%
pivot_wider(names_from = region, values_from = PM2.5_avg) %>%
mutate(
gap = `East Village` - Weighted_Control,
# 標記政策前後
post_policy = as.numeric(week >= intervention_date)
)
# 2. 繪製差距圖
sdid_gap_plot <- sdid_gap_data %>%
ggplot(aes(x = week, y = gap, color = factor(post_policy))) +
geom_line(color = "black", linewidth = 0.8) +
# 政策介入點
geom_vline(xintercept = as.numeric(intervention_date), linetype = "dashed", color = "red") +
# 參考線：差距為零
geom_hline(yintercept = 0, linetype = "solid", color = "gray50") +
# 標記政策後平均差距
geom_point(aes(x = week, y = gap), color = "black", size = 1.5) +
labs(
title = "SDID 政策效果：PM2.5 差距 (Gap)",
subtitle = "East Village 實際值 - 加權控制組值",
y = "差距 (µg/m³)",
x = "週"
) +
scale_color_manual(values = c("0" = "#56B4E9", "1" = "#E69F00"), guide = "none") + # 顏色僅用於區分點
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5))
print(sdid_gap_plot)
